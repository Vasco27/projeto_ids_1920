{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def als_recommender(R, alpha = 40, iterations = 10, lmbda = 0.1, latent = 10):\n",
    "    \n",
    "    \"\"\"\n",
    "    Derivatives of the cost function, which will be iteratively alternating updated.\n",
    "    x_u -> user vector\n",
    "    y_m -> movie vector\n",
    "    \n",
    "    x_u = ((Y.T*Y + Y.T*(Cu - I) * Y) + lambda*I)^-1 * (Y.T * Cu * p(u))\n",
    "    y_m = ((X.T*X + X.T*(Cm - I) * X) + lambda*I)^-1 * (X.T * Cm * p(m))\n",
    " \n",
    "    Args:\n",
    "        R (pivot_table): user-by-item tensor\n",
    " \n",
    "        alpha (int): The rate in which we'll increase our confidence in a user or movie, \n",
    "        according to how many ratings they have\n",
    " \n",
    "        iterations (int): How many times we alternate between fixing and \n",
    "        updating our user and movie vectors\n",
    " \n",
    "        lmbda (float): Regularization to prevent overfitting\n",
    " \n",
    "        latent (int): How many latent features we want to compute.\n",
    "    \n",
    "    Returns:     \n",
    "        X (matrix): user vectors of size users-by-latent\n",
    "        \n",
    "        Y (matrix): item vectors of size items-by-latent\n",
    "     \"\"\"\n",
    "\n",
    "    #confidence = alpha * rui\n",
    "    confidence = (R * alpha)\n",
    "\n",
    "    n_users, n_movies = R.shape\n",
    "\n",
    "    X = sparse.csr_matrix(np.random.normal(size = (n_users, latent)))\n",
    "    Y = sparse.csr_matrix(np.random.normal(size = (n_movies, latent)))\n",
    "    \n",
    "    #identity matrixes\n",
    "    X_I = sparse.eye(n_users)\n",
    "    Y_I = sparse.eye(n_movies)\n",
    "\n",
    "    #Won't work with the identity of shape (latent, latent) can't add that to shape (n_users, latent)\n",
    "    I = sparse.eye(latent)\n",
    "    lI = lmbda * I\n",
    "    \n",
    "    #lX = lmbda * X_I\n",
    "    #lY = lmbda * Y_I\n",
    "    \n",
    "    \n",
    "    #Algorithm for alternating between updating users and movies vectors\n",
    "    for i in range(iterations):\n",
    "        \n",
    "        print ('iteration', i+1, 'of', iterations)\n",
    "        \n",
    "        #updated in every interation\n",
    "        yTy = np.dot(Y.T, Y)\n",
    "        xTx = np.dot(X.T, X)\n",
    "        \n",
    "        #Fix Y (movies) and estimate X (users)\n",
    "        for user in range(n_users):\n",
    "            \n",
    "            print(\"user:\", user)\n",
    "            \n",
    "            row = confidence[user,:].toarray()\n",
    "            print(\"row:\", row.shape)\n",
    "            \n",
    "            #Calculate the preference, 0 if the rating doesn't exist, 1 otherwise\n",
    "            Pu = row.copy()\n",
    "            Pu[Pu != 0] = 1.0\n",
    "            print(\"Pu:\", Pu.shape)\n",
    "            \n",
    "            #Cu - I part\n",
    "            CuI = sparse.diags(row, [0])\n",
    "            Cu = CuI + Y_I\n",
    "            print(\"CuI:\", CuI.shape, \"Cu:\", Cu.shape)\n",
    "            \n",
    "            #Calculating the derivative formula for the user vectors\n",
    "            yT_CuI_y = np.dot(np.dot(Y.T, CuI), Y)\n",
    "            print(\"yT_CuI_y:\", yT_CuI_y.shape)\n",
    "            yT_Cu_Pu = np.dot(np.dot(Y.T, Cu), Pu) #Transpose?\n",
    "            print(\"hey:\", yTy.shape, yT_CuI_y.shape, lI.shape, yT_Cu_Pu)\n",
    "            X[user] = spsolve(yTy + yT_CuI_y + lI, yT_Cu_Pu)\n",
    "            \n",
    "        #Fix X (users) and estimate Y (movies)\n",
    "        for movie in range(n_movies):\n",
    "            print(\"movie: \", movie)\n",
    "            #The idea here is the same as the previous loop but to estimate movies this time\n",
    "            \n",
    "            row = confidence[:,movie].T.toarray()\n",
    "            \n",
    "            Pm = row.copy()\n",
    "            Pm[Pm != 0] = 1.0\n",
    "            \n",
    "            #Since CmI = Cm - I then Cm = CmI + I\n",
    "            CmI = sparse.diags(row, [0])\n",
    "            Cm = CmI + X_I\n",
    "            \n",
    "            #Final formula for movie vectors\n",
    "            xT_CmI_X = np.dot(np.dot(X.T, CmI), X)\n",
    "            xT_Cm_Pm = np.dot(np.dot(X.T, Cm), Pm.T)\n",
    "            Y[movie] = spsolve(xTx + xT_CmI_X + lI, xT_Cm_Pm)\n",
    "            \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = list(np.sort(sampled_ratings.movieId.unique()))\n",
    "users = list(np.sort(sampled_ratings.userId.unique()))\n",
    "\n",
    "rows = sampled_ratings.movieId.astype(\"category\").cat.codes.astype(int)\n",
    "cols = sampled_ratings.userId.astype(\"category\").cat.codes.astype(int)\n",
    "\n",
    "#similar to pivot_table\n",
    "pivot_table = sparse.csr_matrix((sampled_ratings.rating, (rows, cols)), shape = (len(movies), len(users)))\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_vectors, movie_vectors = als_recommender(pivot_table, iterations = 4, latent = 5)\n",
    "%time\n",
    "print(user_vectors)\n",
    "movie_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead of pivot_table the als from the implicit library expects a sparse matrix\n",
    "sampled_ratings.movieId = sampled_ratings.movieId.astype(\"category\").cat.codes\n",
    "sampled_ratings.userId = sampled_ratings.userId.astype(\"category\").cat.codes\n",
    "movie_user_matrix = sparse.csr_matrix((sampled_ratings.rating.astype(float), (sampled_ratings.movieId, sampled_ratings.userId)))\n",
    "user_movie_matrix = sparse.csr_matrix((sampled_ratings.rating.astype(float), (sampled_ratings.userId, sampled_ratings.movieId)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 40\n",
    "confidence = (movie_user_matrix * alpha).astype(\"double\")\n",
    "\n",
    "#Als model with 10 latent factor, lambda = 0.1 and 10 alternating iterations\n",
    "als_model = implicit.als.AlternatingLeastSquares(factors = 10, regularization = 0.1, iterations = 10)\n",
    "als_model.fit(confidence)\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This recommendation is supposed to be for the vectors returned by als_recommender()\n",
    "user_vectors = als_model.user_factors\n",
    "movie_vectors = als_model.item_factors\n",
    "\n",
    "movie_vec = movie_vectors[10].T\n",
    "\n",
    "scores = np.dot(movie_vectors, movie_vec)\n",
    "top_10 = np.argsort(scores)[::-1][:10]\n",
    "\n",
    "\n",
    "movies = []\n",
    "movie_scores = []\n",
    "\n",
    "for i in top_10:\n",
    "    #get first occorrence of the similar movie and get its title\n",
    "    movies.append(sampled_ratings.loc[sampled_ratings.movieId == i].title.iloc[0])\n",
    "    movie_scores.append(scores[i])\n",
    "    \n",
    "movies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
